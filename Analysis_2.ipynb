{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c89aaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.collocations import *\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import nltk, re, string\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import math\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from nltk.stem.porter import *\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from nltk.stem.porter import*\n",
    "import os\n",
    "import sys\n",
    "from sklearn import feature_extraction\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import operator\n",
    "\n",
    "\n",
    "\n",
    "# Read created dictionary\n",
    "pattern=r'\\w[\\w\\',-]*\\w'\n",
    "with open(\"/Users/shenzongqi/Desktop/PythonProject/Stevens/2022_Research/envir_words.txt\",'r') as f:\n",
    "    envir = [line.strip() for line in f]\n",
    "envir = \" \".join(envir)\n",
    "envir=nltk.regexp_tokenize(envir.lower(), pattern)\n",
    "\n",
    "### Read company 10k report\n",
    "\n",
    "def clean_report(text):\n",
    "#tokens=nltk.regexp_tokenize(text.lower(), pattern)\n",
    "    stop_words = stopwords.words('english')\n",
    "### Clean 10k Report data: (Lower, remove stop words)\n",
    "    tokens = [token.strip() \\\n",
    "              for token in nltk.word_tokenize(text.lower()) \\\n",
    "              if token.strip() not in stop_words and \\\n",
    "              token.strip() not in string.punctuation]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "# Tf_Idf matrix\n",
    "\n",
    "# Function1\n",
    "def loadDataSet(tokens):\n",
    "    dataset = tokens\n",
    "    classVec = [0, 1, 0, 1, 0, 1]  # class\n",
    "    return dataset, classVec\n",
    "\n",
    "# Function2\n",
    "def feature_select(dataset):\n",
    "    # Total word frequency statistics\n",
    "    doc_frequency = defaultdict(int) #Record the number of occurrences of each word, which can be understood as a variable-length list, as long as you index it, it will automatically expand the column\n",
    "    for file in dataset:\n",
    "        for word in file:\n",
    "            doc_frequency[word] += 1\n",
    "    # Calculate the TF value of each word\n",
    "    word_tf = {}  # Store the tf value of each word\n",
    "    for i in doc_frequency:\n",
    "        word_tf[i] = doc_frequency[i] / sum(doc_frequency.values()) #sum(doc.frequency.values)\n",
    "\n",
    "    # Calculate the IDF value of each word\n",
    "    doc_num = len(dataset)\n",
    "    word_idf = {}  # Store the idf value of each word\n",
    "    word_doc = defaultdict(int)  # Stores the number of documents that contain the word\n",
    "    for word in doc_frequency:\n",
    "        for file in dataset:\n",
    "            if word in file:\n",
    "                word_doc[word] += 1\n",
    "    #\n",
    "    for word in doc_frequency:\n",
    "        word_idf[word] = math.log(doc_num / (word_doc[word] + 1))\n",
    "\n",
    "    # Calculate the value of TF*IDF for each word\n",
    "    word_tf_idf = {}\n",
    "    for word in doc_frequency:\n",
    "        word_tf_idf[word] = word_tf[word] * word_idf[word]\n",
    "\n",
    "    # Sort dictionary by value from largest to smallest\n",
    "    dict_feature_select = sorted(word_tf_idf.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    return dict_feature_select\n",
    "\n",
    "\n",
    "#####Test\n",
    "def Analysis_10k(text):\n",
    "    tokens = clean_report(text)\n",
    "    data_list, label_list = loadDataSet(tokens)\n",
    "    features = feature_select(data_list)  # TF-IDF values for all words\n",
    "    df = pd.DataFrame(features)\n",
    "    Fin = sum(df[1] / len(df[1]))\n",
    "    return Fin\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Loop all files in dictionary\n",
    "import os\n",
    "import codecs\n",
    "path = \"/Users/shenzongqi/Desktop/PythonProject/Stevens/2022_Research/Data/inputmda_01\" #folder directory\n",
    "files= os.listdir(path) #Get the names of all files in a folder\n",
    "scores = []\n",
    "for file in files: #Traverse folders\n",
    "    position = path+'//'+ file #Construct an absolute path, \"\\\\\", one of '\\' is an escape character\n",
    "    print (position)\n",
    "    with codecs.open(position, 'r', encoding='utf-8',\n",
    "                     errors='ignore') as f:\n",
    "        text = [line.strip() for line in f]\n",
    "        text = text[0]\n",
    "        score = Analysis_10k(text)\n",
    "        score = (file[:-4],score)\n",
    "    scores.append(score)\n",
    "scores = pd.DataFrame(scores)\n",
    "print (scores)\n",
    "scores.columns = [\"CIK\",\"Score\"]\n",
    "\n",
    "\n",
    "scores.to_excel(\"/Users/shenzongqi/Desktop/PythonProject/Stevens/2022_Research/Data/scores.xls\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f918d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "scores_read = pd.read_excel(\"/Users/shenzongqi/Desktop/PythonProject/Stevens/2022_Research/Data/scores.xls\")\n",
    "\n",
    "def add_Year(df):\n",
    "    # Creat column Year with 0\n",
    "    df['Year'] = 0\n",
    "    for i in range(0, 46887):\n",
    "        s = df.iloc[i, 0]\n",
    "        df.iloc[i, 0] = s[:-4]\n",
    "        df.iloc[i, 2] = s.split('-')[1]\n",
    "    # add 20; change column names\n",
    "    for i in range(0, 46887):\n",
    "        df.iloc[i, 2] = \"20\" + df.iloc[i, 2]\n",
    "\n",
    "    df[\"CIK\"] = 0\n",
    "    for i in range(0, 46887):\n",
    "        s = df.iloc[i, 0]\n",
    "        df.iloc[i, 3] = s.split('_')[0]\n",
    "        df.iloc[i,0] = s.split('_')[1]\n",
    "    return df\n",
    "\n",
    "scores = add_Year(scores_read)\n",
    "#scores.to_excel(\"/Users/shenzongqi/Desktop/PythonProject/Stevens/2022_Research/Data/scores_Year.xls\", index=False)\n",
    "scores = pd.read_excel(\"/Users/shenzongqi/Desktop/PythonProject/Stevens/2022_Research/Data/scores_Year.xls\")\n",
    "\n",
    "\n",
    "\n",
    "Co_name = pd.read_csv(\"/Users/shenzongqi/Desktop/PythonProject/Stevens/2022_Research/Data/CIK-Co_name1993-2021.csv\")\n",
    "Co_name.info()\n",
    "Co_name = Co_name[[\"CIK\",\"ACC_NUM\",\"FORM_TYPE\",\"CoName\"]]\n",
    "# names = Co_name.loc[Co_name[]]\n",
    "\n",
    "# change CIK to int type\n",
    "scores['CIK']=scores['CIK'].astype('int64')\n",
    "Co_name['CIK']=Co_name['CIK'].astype('int64')\n",
    "\n",
    "# merge\n",
    "df2 = pd.merge(scores, Co_name, on='ACC_NUM')\n",
    "fin_data = df2.loc[df2.iloc[:,5] == '10-K',:]\n",
    "fin_data.info()\n",
    "fin_data_2 = fin_data.drop(labels='CIK_x',axis=1)\n",
    "fin_data_2.drop_duplicates()\n",
    "fin_data_2.rename(columns = {\"CIK_y\":\"CIK\"}, inplace=True)\n",
    "#fin_data_2.to_excel(\"/Users/shenzongqi/Desktop/PythonProject/Stevens/2022_Research/Data/Score_Coname.xls\", index=False)\n",
    "\n",
    "#_________________________________________________________________________________________________________________________\n",
    "fin_data_2 = pd.read_excel(\"/Users/shenzongqi/Desktop/PythonProject/Stevens/2022_Research/Data/Score_Coname.xls\")\n",
    "\n",
    "\n",
    "\n",
    "# merge data with ticker\n",
    "\n",
    "ticker = pd.read_excel(\"/Users/shenzongqi/Desktop/PythonProject/Stevens/2022_Research/Data/ticker.xlsx\")\n",
    "newDF_withticker = pd.merge(fin_data_2, ticker, on='CIK')\n",
    "newDF_withticker.drop([\"Unnamed: 0\",\"Unnamed: 0.1\"],axis=1, inplace = True)\n",
    "#newDF_withticker.to_excel(\"/Users/shenzongqi/Desktop/PythonProject/Stevens/2022_Research/Data/Year_Scores/newDF_withticker.xlsx\")\n",
    "## newDF_withticker: ACC_NUM + Score + Year + CIK + FORM_TYPE + CoName + Tikcer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### start from here\n",
    "import pandas as pd\n",
    "newDF_withticker = pd.read_excel(\"/Users/shenzongqi/Desktop/PythonProject/Stevens/2022_Research/Data/Year_Scores/newDF_withticker.xlsx\")\n",
    "\n",
    "##################################################################################################\n",
    "sc_2017 = newDF_withticker.loc[newDF_withticker.iloc[:,3] == 2017,:]\n",
    "sc_2017.drop_duplicates(subset=['CoName'],inplace = True)\n",
    "sc_2017.drop_duplicates(subset=['Ticker'],inplace = True)\n",
    "# check unique\n",
    "points = sc_2017.CoName.unique()\n",
    "sc_2017.to_excel(\"/Users/shenzongqi/Desktop/PythonProject/Stevens/2022_Research/Data/Year_Scores/sc_2017.xlsx\")\n",
    "\n",
    "##################################################################################################\n",
    "sc_2018 = newDF_withticker.loc[newDF_withticker.iloc[:,3] == 2018 ,:]\n",
    "sc_2018.drop_duplicates(subset=['CoName'],inplace = True)\n",
    "sc_2018.drop_duplicates(subset=['Ticker'],inplace = True)\n",
    "# check unique\n",
    "points = sc_2018.CoName.unique()\n",
    "sc_2018.to_excel(\"/Users/shenzongqi/Desktop/PythonProject/Stevens/2022_Research/Data/Year_Scores/sc_2018.xlsx\")\n",
    "\n",
    "##################################################################################################\n",
    "sc_2019 = newDF_withticker.loc[newDF_withticker.iloc[:,3] == 2019,:]\n",
    "sc_2019.drop_duplicates(subset=['CoName'],inplace = True)\n",
    "sc_2019.drop_duplicates(subset=['Ticker'],inplace = True)\n",
    "# check unique\n",
    "points = sc_2019.CoName.unique()\n",
    "sc_2019.to_excel(\"/Users/shenzongqi/Desktop/PythonProject/Stevens/2022_Research/Data/Year_Scores/sc_2019.xlsx\")\n",
    "\n",
    "##################################################################################################\n",
    "sc_2020 = newDF_withticker.loc[newDF_withticker.iloc[:,3] == 2020 ,:]\n",
    "sc_2020.drop_duplicates(subset=['CoName'],inplace = True)\n",
    "sc_2020.drop_duplicates(subset=['Ticker'],inplace = True)\n",
    "# check unique\n",
    "points = sc_2020.CoName.unique()\n",
    "sc_2020.to_excel(\"/Users/shenzongqi/Desktop/PythonProject/Stevens/2022_Research/Data/Year_Scores/sc_2020.xlsx\")\n",
    "\n",
    "##################################################################################################\n",
    "sc_2021 = newDF_withticker.loc[newDF_withticker.iloc[:,3] == 2021,:]\n",
    "sc_2021.drop_duplicates(subset=['CoName'],inplace = True)\n",
    "sc_2021.drop_duplicates(subset=['Ticker'],inplace = True)\n",
    "# check unique\n",
    "points = sc_2021.CoName.unique()\n",
    "sc_2021.to_excel(\"/Users/shenzongqi/Desktop/PythonProject/Stevens/2022_Research/Data/Year_Scores/sc_2021.xlsx\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###################\n",
    "# reload file\n",
    "import pandas as pd\n",
    "### Read xlsx file for each year\n",
    "sc_2017 = pd.read_excel(\"/Users/shenzongqi/Desktop/PythonProject/Stevens/2022_Research/Data/Year_Scores/sc_2017.xlsx\")\n",
    "sc_2017[\"Judge\"] = 0\n",
    "sc_2017.loc[sc_2017[\"Score\"] > 0.04, \"Judge\"] = \"Yes\"\n",
    "sc_2017.loc[sc_2017[\"Ticker\"]==\"\", \"Score\"]\n",
    "\n",
    "\n",
    "sc_2018 = pd.read_excel(\"/Users/shenzongqi/Desktop/PythonProject/Stevens/2022_Research/Data/Year_Scores/sc_2018.xlsx\")\n",
    "sc_2018[\"Judge\"] = 0\n",
    "sc_2018.loc[sc_2018[\"Score\"] > 0.04, \"Judge\"] = \"Yes\"\n",
    "sc_2018.loc[sc_2018[\"Ticker\"]==\"aapl\", \"Score\"]\n",
    "\n",
    "sc_2019 = pd.read_excel(\"/Users/shenzongqi/Desktop/PythonProject/Stevens/2022_Research/Data/Year_Scores/sc_2019.xlsx\")\n",
    "sc_2019[\"Judge\"] = 0\n",
    "sc_2019.loc[sc_2019[\"Score\"] > 0.04, \"Judge\"] = \"Yes\"\n",
    "sc_2019.loc[sc_2019[\"Ticker\"]==\"aapl\", \"Score\"]\n",
    "\n",
    "sc_2020 = pd.read_excel(\"/Users/shenzongqi/Desktop/PythonProject/Stevens/2022_Research/Data/Year_Scores/sc_2020.xlsx\")\n",
    "sc_2020[\"Judge\"] = 0\n",
    "sc_2020.loc[sc_2020[\"Score\"] > 0.04, \"Judge\"] = \"Yes\"\n",
    "sc_2020.loc[sc_2020[\"Ticker\"]==\"aapl\", \"Score\"]\n",
    "\n",
    "sc_2021 = pd.read_excel(\"/Users/shenzongqi/Desktop/PythonProject/Stevens/2022_Research/Data/Year_Scores/sc_2021.xlsx\")\n",
    "sc_2021[\"Judge\"] = 0\n",
    "sc_2021.loc[sc_2021[\"Score\"] > 0.04, \"Judge\"] = \"Yes\"\n",
    "sc_2021.loc[sc_2021[\"Ticker\"]==\"aapl\", \"Score\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "sc_non = newDF_withticker.loc[newDF_withticker.iloc[:,2] != 0, \"Score\"]\n",
    "np.mean(sc_non)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9912d795",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22eec33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
